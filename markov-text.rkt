#lang racket

;;;;----------------------------------------------------------------------------

;;;; This file contains code that can randomly generate text using
;;;; markov-chains. Given a corpus of training data, the program outputs text
;;;; generated by looking at the previous n-gram, and selecting the next word
;;;; based on the probability of that word appearing after the particular
;;;; gram.
;;;;
;;;; TODO: Now that it appears to work, make it faster.

;;;;----------------------------------------------------------------------------

(require racket/dict)

;;; Convert a list into a set of n-grams.
(define (n-grams n words)
  (define (helper words so-far)
    (cond ((< (length words) n) so-far)
	  (else (helper (rest words)
			(cons (take words n) so-far)))))
  (reverse (helper words null)))

;;; For each n-gram given, generate a list of words that follow it. This
;;; assumes that the n-grams are in the order in which they appear in the
;;; original text (i.e. they came right from the above n-grams function).
(define (train table grams)
  (define (helper grams so-far)
    (cond
     ((< (length grams) 2) so-far)    ; Nothing follows the last n-gram.
     (else
      (define word (last (second grams)))
      (helper (rest grams)
	      (hash-update so-far
			   (first grams)
			   ;; Add the new word to the list of words.
			   ;; TODO: Make this better: we should be counting
			   ;; the occurances of each word for later processing.
			   (lambda (words) (dict-update words word add1 0))
			   null)))))
  (helper grams table))

;;; Pick a random key out of a hash table.
(define (random-key table)
  (list-ref (hash-keys table)
	    (random (hash-count table))))

;;; Given a transition table and an n-gram, compute the next symbol based on
;;; the frequencies.
(define (next-step table n-gram)
  (define numbers (hash-ref table n-gram null))

  (define (helper nums lowest)
    (cond ((empty? nums)
	   ;; TODO: Maybe return false here and pick a random hash key in
	   ;; the object instead...
	   (first (random-key table)))
	  (else
	   (define num (random (apply + (map cdr numbers))))
	   (define p (first nums))
	   (define upper (cdr p))
	   (if (< num (+ upper lowest))
	       (car p)
	       (helper (rest nums) upper)))))
  (helper numbers 0))

;;; Constructor function for building a markov process.
(define (make-markov-process n)
  (define the-table (make-immutable-hash))
  (define gram null)

  ;; Train the markov process with the input symbols.
  (define (train-it symbols)
    (set! the-table (train the-table (n-grams n symbols))))

  ;; Initialize it with the first n-gram.
  (define (start n-gram) (set! gram n-gram))

  ;; Fetch the next word. Successive calls return successive
  ;; symbols.
  (define (get-next)
    (define result (next-step the-table gram))
    (set! gram (append (rest gram) (list result)))
    result)

  ;; The main dispatcher.
  (lambda (message)
    (cond ((equal? message 'train) train-it)
	  ((equal? message 'get) the-table)
	  ((equal? message 'start) start)
	  ((equal? message 'next) (get-next))
	  (else #f))))

;;;-----------------------------------------------------------------------------
;;; Test code.

(define m (make-markov-process 3))
(define material (file->lines "james.txt"))

(for ((l material))
  ((m 'train) (string-split l)))

((m 'start) (list "the" "news"))

(define (generate-text n)
  (string-join (for/list ((i (in-range n)))
		 (m 'next))))
